"""
Contact Detection System using YOLO + CNN Classifier with Camera Tuning

Description:
This script performs real-time contact classification from webcam input using:
    - YOLOv8 (Ultralytics) for marker detection (segmentation or box-based)
    - Contour extraction and ellipse fitting to isolate each marker
    - CNN classifier (.pth) to classify as "Contact" or "Non-Contact"
    - Optional: camera tuning via `v4l2-ctl` for consistent lighting

Outputs:
    - YOLO bounding or segmentation mask
    - Ellipse fitted to valid contours
    - CNN label prediction ("Contact" or "Non-Contact")
    - Real-time FPS for YOLO, CNN, and total pipeline

Controls:
    - 'q': Quit the program

Dependencies:
    - opencv-python
    - numpy
    - torch
    - torchvision
    - ultralytics
    - v4l2-ctl (for Linux camera control)

"""


import cv2
import numpy as np
import torch
from torchvision import transforms
import time
from ultralytics import YOLO
import os

# ========== CONFIG ==========
#Old8m
#model = YOLO('https://hub.ultralytics.com/models/Rr0ta5z4hkQFFLPyMKbM')
#NEw8m
#model = YOLO('https://hub.ultralytics.com/models/FXQZDSnabILUcO4J8HNB')
#BlackWhite8m
model = YOLO('https://hub.ultralytics.com/models/tOiUrSrUhF6MlFafEx3g')

cnn_path = 'Contact_classifier_model/contact_classifier/contact_classifier_2.pth'

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
cnn_model = torch.load(cnn_path, map_location=device)
cnn_model.eval().to(device)

transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((64, 64)),
    transforms.ToTensor(),
    transforms.Normalize([0.5]*3, [0.5]*3)
])

cap = cv2.VideoCapture(0)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

os.system("v4l2-ctl -d /dev/video0 --set-ctrl=auto_exposure=1")
os.system("v4l2-ctl -d /dev/video0 --set-ctrl=exposure_time_absolute=50")
os.system("v4l2-ctl -d /dev/video0 --set-ctrl=brightness=3")
os.system("v4l2-ctl -d /dev/video0 --set-ctrl=contrast=25")
os.system("v4l2-ctl -d /dev/video0 --set-ctrl=hue=-2")
os.system("v4l2-ctl -d /dev/video0 --set-ctrl=saturation=60")
os.system("v4l2-ctl -d /dev/video0 --set-ctrl=sharpness=2")
os.system("v4l2-ctl -d /dev/video0 --set-ctrl=gamma=100")
os.system("v4l2-ctl -d /dev/video0 --set-ctrl=backlight_compensation=1")
os.system("v4l2-ctl -d /dev/video0 --set-ctrl=gain=0")
os.system("v4l2-ctl -d /dev/video0 --set-ctrl=power_line_frequency=1") # 1=50Hz, 2=60Hz


while True:
    ret, frame = cap.read()
    if not ret:
        break

    start_time = time.time()


    results = model.predict(source=frame, conf=0.7, verbose=False, imgsz=640)
    detect_time = time.time()

    # === Mask/ellipse logic ===
    # Use segmentation mask if model supports, else use boxes
    mask_canvas = np.zeros((frame.shape[0], frame.shape[1]), dtype=np.uint8)

    # --- If using segmentation model ---
    found_poly = False
    for r in results:
        if hasattr(r, "masks") and r.masks is not None and hasattr(r.masks, "xy"):
            for poly in r.masks.xy:
                pts = np.array(poly, dtype=np.int32)
                cv2.fillPoly(mask_canvas, [pts], 255)
            found_poly = True

    # --- Fallback: If not segmentation, use bbox rectangles ---
    if not found_poly:
        for r in results:
            for box in r.boxes.xyxy.cpu().numpy().astype(int):
                x1, y1, x2, y2 = box
                cv2.rectangle(mask_canvas, (x1, y1), (x2, y2), 255, -1)

    # Morph ops
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
    mask_clean = cv2.morphologyEx(mask_canvas, cv2.MORPH_OPEN, kernel)
    mask_clean = cv2.morphologyEx(mask_clean, cv2.MORPH_CLOSE, kernel)

    # Find contours & fit ellipses
    contours, _ = cv2.findContours(mask_clean, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    ellipse_canvas = np.zeros((frame.shape[0], frame.shape[1], 3), dtype=np.uint8)
    for cnt in contours:
        if len(cnt) >= 5:
            area = cv2.contourArea(cnt)
            if 80 < area < 4000:  # adjust 4000 depending on your largest real marker
                ellipse = cv2.fitEllipse(cnt)
                cv2.ellipse(ellipse_canvas, ellipse, (255, 255, 255), -1)

    # --- Classify with CNN ---
    input_tensor_cnn = transform(ellipse_canvas).unsqueeze(0).to(device)
    with torch.no_grad():
        output = cnn_model(input_tensor_cnn)
        _, predicted = torch.max(output, 1)
        label = "Contact" if predicted.item() == 0 else "Non-Contact"
    class_time = time.time()

    # --- Overlay FPS and label ---
    ellipse_canvas_disp = ellipse_canvas.copy()
    detect_fps = 1.0 / (detect_time - start_time)
    class_fps = 1.0 / (class_time - detect_time)
    total_fps = 1.0 / (class_time - start_time)

    cv2.putText(ellipse_canvas_disp, f"YOLO FPS: {detect_fps:.2f}", (10, 25),
                cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0,255,255), 1)
    cv2.putText(ellipse_canvas_disp, f"CNN FPS: {class_fps:.2f}", (10, 45),
                cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255,128,0), 1)
    cv2.putText(ellipse_canvas_disp, f"Total FPS: {total_fps:.2f}", (10, 75),
                cv2.FONT_HERSHEY_SIMPLEX, 0.4, (200,200,255), 1)
    cv2.putText(ellipse_canvas_disp, f"{label}", (10, 105),
                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,0) if label=="Contact" else (0,0,255), 2)
    
    cv2.imshow("Camera", frame)

    cv2.imshow("Detection + Ellipse + Classification", ellipse_canvas_disp)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
